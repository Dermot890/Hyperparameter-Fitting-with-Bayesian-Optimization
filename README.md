# Hyperparameter-Fitting-with-Bayesian-Optimization

Bayesiab optimization is a strategy that works well with objective functions with unknown gradient and which are computationally expensive. As such it is a good way to fit hyperparameters for ML algorithms - define an objective that takes a set of hyperparameters as  its argument and outputs  the cross validation score of the model fitted with those parameters. Here I try this idea out on a few models.
